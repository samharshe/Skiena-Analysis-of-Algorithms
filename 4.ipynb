{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Lecture 4: Elementary Data Structures](https://www.youtube.com/watch?v=vg2u8Hbb6lE&list=PLOtl7M3yp-DX6ic0HGT0PUX_wiNmkWkXx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the problem of the day is really useful. I should do more problems like that."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we must build our algorithms from well-defined data structures."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can specify data structures in terms of the abstract operations they support."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stack supports push and pop."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contiguous data structures vs linked data structures.  \n",
    "contiguous: you are working within one giant slab of memory.  \n",
    "    • arrays  \n",
    "    • matrices  \n",
    "    • heaps  \n",
    "    • hash tables  \n",
    "linked: multiple distinct chunks of memory bound together by pointers  \n",
    "    • linked lists  \n",
    "    • trees  \n",
    "    • graph adjacency lists"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array is the mother of all contiguous data strucutres.   \n",
    "fixed-size data records accessed by an index.  \n",
    "look-up is fast if you know the index.  \n",
    "all data. no meta-data.  \n",
    "\n",
    "one problem: you must fix the size of arrays in advance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dynamic arrays start as size 1 and double in size each time they run out of space.  \n",
    "we need only double $ log_2(n) $ times to make enough space.  \n",
    "we need to copy the first element $ log_2(n) $ times, which suggests the time complexity of the array is $ nlog_2(n) $, since we have $ n $ elements to be copied $ log_2(n) $ times each.  \n",
    "in fact, though, the second element is copied $ log_2(n) / 2 $ times, and so on, until half the elements are never copied, and summing all these copying operations only gives us $ n $ of them in total.  \n",
    "\n",
    "this dynamic array is in $\\Theta(n)$, so it's not so bad."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*p is the item pointed to by pointer p.  \n",
    "&p is the pointer of the item p."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linked list contain two parts: data item, link field.  \n",
    "what they contain, and where to find their successor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to search through a linked list: check if an item equals your targer; if not, check its successor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is in $\\Theta(n)$, obviously.  \n",
    "one way to think about it: $T(n) = T(n-1) + O(n)$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to insert an item in the head of the list, allocate memory for it and link it to the pointer of the first element. this is easy.  \n",
    "to delete something from a linked list, you need to search through to find the element to be deleted's predecessor (so that you can change what it points to), which takes $\\Theta(n)$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why use linked lists?  \n",
    "overflow does not occur unless the memory is totally full.  \n",
    "insertions and deletions are simpler than for arrays.  \n",
    "moving pointers can be easier than moving the items themselves.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doubly-linked lists contain a data cell, a predecessor pointer, and a successor pointer.  \n",
    "drives down big-Oh cost, but drives up fixed cost."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stacks and queues store items based on the order in which they were received, not based on their content."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stack: last in, first out.  \n",
    "push/pop.  \n",
    "queue: first in, first out.  \n",
    "enqueue, dequeue.  \n",
    "\n",
    "all the above operations happen in constant time.  \n",
    "\n",
    "if you don't care about the order of access, stacks and queues are equally good."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dictionaries are one of the most important classes of data structure.  \n",
    "they support:  \n",
    "1. Search(S, k), which gives the pointer of the element of key k, if such an element exists.  \n",
    "2. Insert(S,x), which adds x to the dictionary.\n",
    "3. Delete(S, x), which removes the item with pointer x from the dictionary.  \n",
    "4. Min(S), Max(S), which return the first and last of the keys, ordered alphabetically.  \n",
    "5. Predecessor(S,x), Successor(S,x), give the element (or the pointer of the elemtent) logically before or after the x, wh ere S is totally orderd."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unsorted arrays:  \n",
    "1. Search(S,k) sequential search $O(n)$.  \n",
    "2. Insert(S,x) insert in the first open spot $O(1)$.  \n",
    "3. Delete(S,x) copy the nth item into the xth spot and decrement the size of the array by 1.  \n",
    "4. Min(S,x), Max(S,x) sequential search $O(n)$.\n",
    "5. Successor(S,x), Predecessor(S,x) sequential search $O(n)$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sorted arrays:  \n",
    "1. Search(S,k) binary search $O(lg(n))$.  \n",
    "2. Insert(S,x) search, then move to make space $O(n)$.  \n",
    "3. Delete(S,x) delete, then move up to fill the hole $O(n)$.  \n",
    "4. Min(S,x), Max(S) first or last element $O(1)$.  \n",
    "5. Successor(S,x), Predecessor(S,x) add or subtract 1 from the pointer $O(1)$. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reflections"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the two main types of data structures are contiguous and linked.  \n",
    "data structures can be defined by the operations one can do on them.  \n",
    "different data structures allow different operations to be done in different time.  \n",
    "it is so far not too difficult to figure out in what time a given operation can be done on a given data structure."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
