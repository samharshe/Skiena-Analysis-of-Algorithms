{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Lecture 14: Minimum Spanning Trees Continued](https://www.youtube.com/watch?v=oolm2VnJUKw&list=PLOtl7M3yp-DX6ic0HGT0PUX_wiNmkWkXx&index=13)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prim's algorithm: add the smallest edge from the existing tree to a new vertex.  \n",
    "Kruskal's algorithm: add the smallest edge that does not create a cycle.  \n",
    "Kruskal's better on sparse graphs.  \n",
    "Prim's better on dense graphs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kruskal's is in O(mn), but apparently we can do better."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if there is a better algorithm than Kruskal's that chooses different edges, then adding an edge that it does not pick creates a cycle.  \n",
    "however, to remove that cycle, we can remove any other edge that it contains, which must be more expensive than the edge that Kruskal's picked.  \n",
    "thus the other algorithm must be more expensive."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we want to keep track of the components of the graph so we can tell when we make a cycle more quickly so we can speed up our MST algorithm."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "union-find programs.  \n",
    "find(i) tells me the root of the tree containing i.  \n",
    "union(i,j) makes the roots of the trees containing i and j the same.  \n",
    "both in proportion to the height of the tree."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we therefore want to minimize the height of the tree.  \n",
    "we make the small tree point to the large tree when we merge so as not to increase the height."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it's hard to keep track of the height of the tree, so we keep track of the number of nodes instead, and make the tree with fewer nodes point to the tree with more nodes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thus we can check for cycles in logn, so we can run Kruskal's in mlogn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in an unweighted graph, BFS gives shortest path."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "negative cost cycles render the problem meaningless because we can keep looping around indefinitely.  \n",
    "negative cost edges in trees are OK but Dykstra's algo assumes they don't exist. (can't we just modify our weights then by adding the weight of the most negative edge to regularize everything?)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we always know the shortest path to the nearest neighbor: just travel along the edge that connects us to him."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we build a tree of the vertices that we know the shortest path to."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is a lot like Prim's algorith: keep adding edges when we know they are the cheapest way to get to the node they connect us to."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in Prim's algorithm, we are choosing the cheapest edge that gets us from a connected vertex to an unconnected one.  \n",
    "in Dykstra's, we are choosing the edge that we know is the cheapest way to an unconnected vertex, regardless of whether it is the cheapest edge in general.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reflections"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can do Kruskal's in O(mlogn) by checking for cycles in logn by keeping track of the disconnected parts of the graph carefully."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dykstra's algorithm tells us the shortest path by keeping a tree of vertices that we know the shortest path to. the rub is that we always know the shortest path from a to b if a's cheapest edge is (a,b)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
